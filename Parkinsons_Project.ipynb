{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Parkinsons_Project.ipynb","provenance":[{"file_id":"https://github.com/Bhumika-Chopra/Parkinson-s-disease-Classification/blob/main/Parkinsons_Project.ipynb","timestamp":1636710105101}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CUHW-b3vip_I"},"source":["dict_datasetkey = {1:\"Sri Lanka Dataset\", 2: \"Istanbul Uni Dataset\"}\n","glob_feats = ['Subject ID', \n","              'Jitter(local)', 'Jitter(local, absolute)', 'Jitter (rap)', 'Jitter (ppq5)', 'Jitter (ddp)', \n","              'Shimmer (local)', 'Shimmer (local, db)', 'Shimmer (apq3)', 'Shimmer (apq5)', 'Shimmer (apq11)', \n","              'Shimmer (dda)', 'AC', 'NDH', 'HTM', 'Median Pitch', 'Mean Pitch', 'Standard deviation', \n","              'Minimum pitch', 'Maximum pitch', 'Number of pulses', 'Number of periods', 'Mean period', \n","              'Standard deviation of period', 'Fraction of locally unvoiced frames', 'Number of voice breaks', \n","              'Degree of voice breaks', 'status']\n","\n","\n","glob_feats1 = [glob_feats[0]]\n","glob_feats1.extend([\"mu_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"median_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"trim10mean_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"trim25mean_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"sd_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"iqr_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.extend([\"mad_\" + s for s in glob_feats[1:-1]])\n","glob_feats1.append(glob_feats[-1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwF-Iqv2QRyg"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","sns.set(color_codes = True)\n","import scipy.stats as spst"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NjHlx_mT9EO","outputId":"82ddaf00-d8cf-4de5-b01f-9d62e22138bb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B2sgX8cPUkAT"},"source":["img_dir_train = \"{}/drawings/all_together/training/\".format(fdir)\n","img_dir_test = \"{}/drawings/all_together/testing/\".format(fdir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16jFOsl3L7fQ"},"source":["fdir = \"/content/drive/MyDrive/parkinsons_datasets\"\n","str_i = \"iid_\"\n","# str_i = \"\"\n","ds1 = \"{}/{}pd_final1.csv\".format(fdir,str_i)\n","ds2 = \"{}/{}pd_final2.csv\".format(fdir,str_i)\n","if(str_i!=\"\"):\n","  glob_feats = glob_feats1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkxiHjJZ1Bkc"},"source":["print(len(merged_ds.status))\n","print(len(df2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7OnE6UBioYn"},"source":["#EDA\n","df1_feats.describe().T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhDa5tscpBcA"},"source":["df2_feats.describe().T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oaG5ZLBBYhH"},"source":["!!pip install pandas-profiling==2.7.1 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zc5MbTeTpPRe"},"source":["sns.pairplot(df2.drop(glob_feats[0],axis=1),\n","             x_vars=[glob_feats[16],glob_feats[5]],\n","            y_vars=[glob_feats[22],glob_feats[11],glob_feats[24]],hue=\"status\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WY6UI_gFQ1ea"},"source":["sns.pairplot(df2.drop(glob_feats[0],axis=1),\n","             x_vars=[glob_feats[16],glob_feats[5]],\n","            y_vars=[glob_feats[22],glob_feats[11],glob_feats[14],glob_feats[24]],hue=\"status\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bcRnnp3Q3fR"},"source":["def skewkurt(data):\n","  skew_kurt_df = pd.DataFrame(data=data.skew(), columns=[\"Skewness\"])\n","  skew_kurt_df['Kurtosis'] = data.kurtosis()\n","  print(skew_kurt_df)\n","  fig,ax = plt.subplots(5,5,figsize=(26,10))\n","  ax=ax.flatten()\n","  for i in range ( 1, len(data.columns)):\n","      sns.kdeplot(data.iloc[:,i],ax=ax[i])\n","      ax[i].axvline(x=data.iloc[:,i].mean(),ymin=0,ymax=1,color=\"red\")\n","  plt.tight_layout()\n","  plt.show()    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuBxuVz4Rfii"},"source":["def box_kde_plts_all_feat(data,features1):\n","\n","  for features in features1:\n","    try:\n","      data[features].plot(kind=\"box\",figsize=[15,5])\n","      plt.ylim(0,0.5)\n","      plt.hlines(0.1,0,6)\n","      # All amplitude measure factors have outliers and \n","      data[features].plot(kind=\"kde\",figsize=[10,5])\n","      plt.xlim(-0.1,0.5)\n","      plt.ylim(0,30)\n","      plt.show()\n","      plt.clf()\n","      # measure shimmer DDA seems to be normally distributed \n","    except:\n","      print(\"err\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJuk4mypSKXk"},"source":["box_kde_plts_all_feat(df1,glob_feats)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmdyTsyrSf1q"},"source":["from sklearn.model_selection import train_test_split,LeaveOneOut, LeavePOut, cross_validate, KFold\n","\n","def traintest_split(data_feats,data,frac=0.1):\n","  x = data_feats\n","  y = data.status\n","  # print(y.shape)\n","  x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=frac,shuffle=True)\n","  return x_train, x_test,y_train,y_test\n","\n","\n","from sklearn.neural_network import MLPClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekv4RtLkOAoV"},"source":["def shuffle(merged_x_train,merged_y_train,key):\n","  merged_whole = merged_x_train\n","  merged_whole[key] = merged_y_train\n","  merged_whole = merged_whole.sample(frac=1)\n","  return merged_whole.drop([key],axis=1),merged_whole[key]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NalkcYcNUX47"},"source":["\n","kfold = KFold(n_splits=10,shuffle=True)\n","\n","df_imputed = pd.read_csv(fdir + \"/Imputed_data_merge.csv\")\n","df_imputed_y = df_imputed['182']\n","df_imputed_feats = df_imputed.drop(['182'],axis=1)\n","\n","ds_train = df_imputed_feats\n","ds_y_train = df_imputed_y\n","\n","ds_train, ds_y_train = shuffle(ds_train,ds_y_train,'182')\n","\n","# df_imputed_test = pd.read_csv(fdir + \"/Imputed_data_test.csv\")\n","df_imputed_test = pd.read_csv(fdir + \"/Imputed_data_test_merge.csv\")\n","ds_test = df_imputed_test.drop(['182'],axis=1)\n","# ds_test = pd.DataFrame(MinMaxScaler().fit_transform(ds_test))\n","ds_y_test = df_imputed_test['182']\n","ds_test, ds_y_test = shuffle(ds_test,ds_y_test,'182')\n","\n","# ds_train,ds_test,ds_y_train,ds_y_test = traintest_split(merged_ds_feats,merged_ds)\n","\n","# ds_train,ds_test,ds_y_train,ds_y_test = traintest_split(df2_feats,df2)\n","\n","\n","X = np.asarray(ds_train)\n","y = np.array(ds_y_train)\n","# print(y.shape)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9ezsyZa7JhN"},"source":["all_test_accs = {'lr':[],'nb':[],'knn_4':[],'knn_6':[],'svm_poly':[],'svm_rbf':[],'dt':[],'rf':[],'ada':[],'gb':[],'xgb':[],'mlp':[]}\n","\n","# for train_index, test_index in kfold.split(X):\n","\n","#     X_train, X_test = X[train_index], X[test_index]\n","#     y_train, y_test = y[train_index], y[test_index]\n","if(1==1):\n","    X_train, X_test = ds_train,ds_test\n","    y_train,y_test = ds_y_train, ds_y_test\n","    #logistic reg\n","    # temp_lst = []\n","\n","    acc_lr = logistic_regression(X_train,X_test,y_train,y_test)\n","    all_test_accs['lr'].append(acc_lr)\n","    # temp_lst.append(acc_lr)\n","\n","    acc_nb = naive_bayes(X_train,X_test,y_train,y_test)\n","    all_test_accs['nb'].append(acc_nb)\n","    # temp_lst.append(acc_nb)\n","\n","    # acc_knn = knn_bestk(X_train,X_test,y_train,y_test,kmax=4)\n","    # all_test_accs['knn_4'].append(acc_knn)\n","\n","    acc_knn = knn_bestk(X_train,X_test,y_train,y_test,kmax=6)\n","    all_test_accs['knn_6'].append(acc_knn)\n","    # temp_lst.append(acc_knn)\n","\n","\n","    # acc_svm = svm(X_train,X_test,y_train,y_test,kern='poly')\n","    # all_test_accs['svm_poly'].append(acc_svm)\n","    # temp_lst.append(acc_svm)\n","    \n","    acc_svm = svm(X_train,X_test,y_train,y_test,kern='rbf')\n","    all_test_accs['svm_rbf'].append(acc_svm)\n","    \n","    #decison tree\n","    acc_dt = decision_tree(X_train,X_test,y_train,y_test)\n","    all_test_accs['dt'].append(acc_dt)\n","    # temp_lst.append(acc_dt)    \n","    \n","    #random forest\n","    acc_rf = random_forest(X_train,X_test,y_train,y_test)\n","    all_test_accs['rf'].append(acc_rf)\n","    # temp_lst.append(acc_rf)\n","\n","    #addaboost\n","    acc_ada = adaboost(X_train,X_test,y_train,y_test)\n","    all_test_accs['ada'].append(acc_ada)\n","    # temp_lst.append(acc_ada)\n","\n","    #gradient boost\n","    acc_gb = gradient_boost(X_train,X_test,y_train,y_test)\n","    all_test_accs['gb'].append(acc_gb)\n","    # temp_lst.append(acc_gb)\n","\n","    #xgboost\n","    acc_xgb = xgboost_classifier(X_train,X_test,y_train,y_test)\n","    all_test_accs['xgb'].append(acc_xgb)\n","\n","    #MLP \n","    mlp_cl = MLPClassifier(random_state=1, max_iter=800,hidden_layer_sizes=(200,100,50,25),solver='adam').fit(X_train, y_train)\n","    acc_mlp = mlp_cl.score(X_test,y_test)\n","    all_test_accs['mlp'].append(acc_mlp)\n","    # temp_lst.append(acc_mlp)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EY_yPhGAN7E","outputId":"96a60f16-4493-40b9-b7e9-342b3deba611"},"source":["print(list(kfold.split(X))[0][1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 2 28 29 30 43]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifvy3xvG7AD5"},"source":["for key in all_test_accs.keys():\n","  if (len(all_test_accs[key])>0): \n","    print(\"{}\".format(round(np.mean(all_test_accs[key]),3)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7trFhcuFDzp4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28989ef8-5f22-430f-b5fb-e5c28626771b"},"source":["# xgboost for non merged\n","model_gbcl = XGBClassifier().fit(ds_train, ds_y_train)\n","pred_test_y_gbcl = model_gbcl.predict_proba(ds_test)\n","# print(model_gbcl.score(ds_test,ds_y_test))\n","# pred_test_y_gbcl = mlp_cl.predict_proba(ds_test)\n","fpr_lr, tpr_lr, threshold_lr = roc_curve(ds_y_test,pred_test_y_gbcl[:,1])\n","print(auc(fpr_lr,tpr_lr))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.8126153846153847\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k5yeyfQSFVRO"},"source":["fpr_lr_m = fpr_lr #auc roc 0.75\n","tpr_lr_m = tpr_lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ly8j3wSFEvyy"},"source":[" # Area under the curve, MLP Model:1.00\n","# ROC score for MLP Model: 0.83\n","plt.figure(figsize = [10,5])\n","plt.plot(fpr_lr_m,tpr_lr_m, label = \"MLP, MSR-HD dataset, AUC = 0.693\")\n","plt.plot(fpr_lr,tpr_lr, label = \"MLP, MSR+SL-HD dataset, AUC = 0.813\")\n","plt.plot([0,1],[0,1],\"k--\")\n","plt.xlabel(\"false positive rate\")\n","plt.ylabel(\"true positive rate\")\n","plt.legend()\n","plt.title(\"ROC curve\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FnjeAKuGvfZ"},"source":["adaboost(x_train_1,x_test_1,y_train_1,y_test_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVuurS5vEBYE"},"source":["adaboost(merged_x_train,x_test_1,merged_y_train,y_test_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMdwOkdIU-ss"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix,accuracy_score,classification_report, auc, roc_auc_score, roc_curve\n","\n","def logistic_regression(x_train,x_test,y_train,y_test,if_not_sloo=False):\n","  model_lr = LogisticRegression(max_iter=1500)\n","  # fitting the model \n","  model_lr.fit(x_train,y_train)\n","  pred_y_train_lr = model_lr.predict(x_train)\n","  pred_y_test_lr =  model_lr.predict(x_test)\n","\n","\n","  \n","  # classification report and confusion matrix \n","  if if_not_sloo is True:\n","    \n","    print(\"Logistic Regression accuracy on the train set:\",accuracy_score(pred_y_train_lr,y_train))\n","    print(\"Logistic Regression accuracy on the test set :\",accuracy_score(pred_y_test_lr,y_test))\n","\n","    cm_lr = confusion_matrix(y_test,pred_y_test_lr,labels=[1,0])\n","    cm_lr_df = pd.DataFrame(cm_lr,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"] ),\n","                          index = (i for i in [1,0]))\n","    sns.heatmap(cm_lr_df,annot= True, cmap= \"YlGnBu\")\n","    print(\"Classification report for LR model \\n\\n\",classification_report(y_test,pred_y_test_lr,labels=[1,0]))\n","    proab_test_y_lr = model_lr.predict_proba(x_test) \n","    fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test,proab_test_y_lr[:,1])\n","    print(\"Area under the curve, Logistic Regression Model:%.2f\"% auc(fpr_lr,tpr_lr))\n","    print(\"ROC score for Logistic Regression Model: %.2f\"%roc_auc_score(y_test,pred_y_test_lr))\n","    plt.figure(figsize = [10,5])\n","    plt.plot(fpr_lr,tpr_lr, label = \"logistic Regression\")\n","    plt.plot([0,1],[0,1],\"k--\")\n","    #plt.plot(threshold_lr.round(2))\n","    plt.legend()\n","    plt.show()\n","  \n","  return accuracy_score(pred_y_test_lr,y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eQ_W-Q2bnam"},"source":["from sklearn.naive_bayes import GaussianNB\n","\n","def naive_bayes(x_train,x_test,y_train,y_test,if_not_sloo=False):\n","  model_nb = GaussianNB()\n","  # training the model \n","  model_nb.fit(x_train,y_train)\n","  pred_train_y_nb = model_nb.predict(x_train)\n","  pred_test_y_nb = model_nb.predict(x_test)\n","\n","  if if_not_sloo is False:\n","    return accuracy_score(y_test,pred_test_y_nb)\n","\n","  print(\"Accuracy of NB on train set :\", accuracy_score(y_train,pred_train_y_nb))\n","  print(\"Accuracy of NB on test set :\", accuracy_score(y_test,pred_test_y_nb))\n","  # NB has a lesser accuracy than logistic regression \n","  # checking the classification report and confusion matrix \n","  cm_nb = confusion_matrix(y_test,pred_test_y_nb, labels=[1,0])\n","  cm_nb_df = pd.DataFrame(cm_nb,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_nb_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"Classification report Naive Bayes:\\n\",classification_report(y_test,pred_test_y_nb,labels=[1,0]))\n","  proab_test_y_nb = model_nb.predict_proba(x_test) \n","  fpr_nb, tpr_nb, threshold_nb = roc_curve(y_test,proab_test_y_nb[:,1])\n","  print(\"Area under the curve, Naive Bayes Model:%.2f\"% auc(fpr_nb,tpr_nb))\n","  print(\"ROC score for naive Bayes Model: %.2f\"%roc_auc_score(y_test,pred_test_y_nb))\n","  plt.figure(figsize = [10,5])\n","  plt.plot(fpr_nb,tpr_nb,label=\"Naive Bayes\")\n","  #plt.plot(threshold_lr)\n","  #plt.plot(threshold_nb)\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWkXlXnUbDX2"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","def knn_bestk(x_train,x_test,y_train,y_test,kmax=4,if_not_sloo=False):\n","  model_knn = KNeighborsClassifier(n_neighbors=kmax,weights = \"distance\")\n","  model_knn.fit(x_train,y_train)\n","  pred_train_y_knn=model_knn.predict(x_train)\n","  pred_test_y_knn = model_knn.predict(x_test)\n","  \n","  if if_not_sloo is False:\n","    return accuracy_score(y_test,pred_test_y_knn)\n","\n","  print(\"Accuracy of KNN on train set :\", accuracy_score(y_train,pred_train_y_knn))\n","  print(\"Accuracy of KNN on test set :\", accuracy_score(y_test,pred_test_y_knn))\n","  # 87 percent accuracy, i,proved accuracy with min max scalert to 91 \n","  # classification report and confusion matrix \n","  cm_knn = confusion_matrix(y_test,pred_test_y_knn, labels=[1,0])\n","  cm_knn_df = pd.DataFrame(cm_knn,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_knn_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report KNN:\\n\",classification_report(y_test,pred_test_y_knn,labels=[1,0]))\n","  # Recall 95%  improved to 97 % with min  max scaler \n","  # F1 score 91 , improved to 95  with min max scaler \n","  # Accuracy 90 %  improved to 91 with min max scaler \n","  # checking ROC and AUC\n","  proab_test_y_knn = model_knn.predict_proba(x_test) \n","  fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test,proab_test_y_knn[:,1])\n","  print(\"Area under the curve, KNN Model:%.2f\"% auc(fpr_knn,tpr_knn))\n","  print(\"ROC score for KNN Model: %.2f\"%roc_auc_score(y_test,pred_test_y_knn))\n","  plt.figure(figsize = [10,5])\n","  # plt.plot(fpr_lr,tpr_lr, label = \"logistic Regression\")\n","  # plt.plot(fpr_nb,tpr_nb,label=\"Naive Bayes\")\n","  plt.plot(fpr_knn,tpr_knn,label=\"KNN\")\n","  #plt.plot(threshold_lr)\n","  #plt.plot(threshold_nb)\n","  #plt.plot(threshold_knn)\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-wxGZf5cdAb"},"source":["from sklearn.svm import SVC\n","\n","def svm(x_train,x_test,y_train,y_test,gam='scale',kern=\"rbf\",if_not_sloo = False):\n","  model_svc = SVC(gamma=gam,kernel=kern,C=1, probability=True)\n","  model_svc.fit(x_train,y_train)\n","  pred_train_y_svc=model_svc.predict(x_train)\n","  pred_test_y_svc=model_svc.predict(x_test)\n","  \n","  if if_not_sloo is False:\n","    return accuracy_score(y_test,pred_test_y_svc)\n","\n","  print(\"Accuracy on the train set SVC :\",accuracy_score(y_train,pred_train_y_svc))\n","  print(\"Accuracy on the test set SVC :\",accuracy_score(y_test,pred_test_y_svc))\n","  # confusion Matrix and Classification report \n","  cm_svc = confusion_matrix(y_test,pred_test_y_svc, labels=[1,0])\n","  cm_svc_df = pd.DataFrame(cm_svc,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_svc_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report SVC:\\n\",classification_report(y_test,pred_test_y_svc,labels=[1,0]))\n","  #Recall 97 - recall increased to 1 with in exp 2 (with min max scaler)\n","  # Accuracy 91 - reduced 75 in exp2\n","  # F1 score 95 - reduced to 86 \n","  # ROC and AUC ROC curve \n","  proab_test_y_svc = model_svc.predict_proba(x_test) \n","  fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test,proab_test_y_svc[:,1])\n","  print(\"Area under the curve, SVC Model:%.2f\"% auc(fpr_svc,tpr_svc))\n","  print(\"ROC score for SVC Model: %.2f\"%roc_auc_score(y_test,pred_test_y_svc))\n","  plt.figure(figsize = [10,5])\n","  plt.plot(fpr_svc,tpr_svc,label=\"SVC\")\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5NRg4UpdQUK"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import plot_tree\n","\n","def decision_tree(x_train,x_test,y_train,y_test,crit=\"gini\",maxd=3,rs=1,if_not_sloo = False):\n","  model_dt = DecisionTreeClassifier(criterion=crit,max_depth=maxd, random_state=rs)\n","  model_dt.fit(x_train,y_train)\n","  if if_not_sloo is False:\n","    return model_dt.score(x_test,y_test)\n","  print(\"Training Set Score:\", model_dt.score(x_train,y_train))\n","  print(\"Test Set Score\", model_dt.score(x_test,y_test))\n","  pred_test_y_dt = model_dt.predict(x_test)\n","  # visualizing the decision tree \n","  plt.figure(figsize=[10,5])\n","  plot_tree(model_dt,class_names=[\"1\",\"0\"],feature_names=list(x_train))\n","  cm_dt = confusion_matrix(y_test,pred_test_y_dt, labels=[1,0])\n","  cm_dt_df = pd.DataFrame(cm_dt,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_dt_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report KNN:\\n\",classification_report(y_test,pred_test_y_dt,labels=[1,0]))\n","  # Checking the list of important feature \n","  imp_feature=pd.DataFrame(model_dt.feature_importances_, columns=[\"Important Feature\"],index=x_train.columns)\n","  imp_feature['Important Feature'].loc[imp_feature['Important Feature']>0]\n","  # ROC and AUC curve \n","  proab_test_y_dt = model_dt.predict_proba(x_test) \n","  fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test,proab_test_y_dt[:,1])\n","  print(\"Area under the curve, DT Model:%.2f\"% auc(fpr_dt,tpr_dt))\n","  print(\"ROC score for DT  Model: %.2f\"%roc_auc_score(y_test,pred_test_y_dt))\n","  plt.figure(figsize = [10,5])\n","\n","  plt.plot(fpr_dt,tpr_dt,label=\"Decision Tree\")\n","  #plt.plot(threshold_lr)\n","  #plt.plot(threshold_nb)\n","  #plt.plot(threshold_knn)\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQhXZYQ3dwo7"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","def random_forest(x_train,x_test,y_train,y_test,if_not_sloo = False):\n","  model_rf = RandomForestClassifier(n_estimators=50,random_state=1,max_features=12)\n","  model_rf.fit(x_train,y_train)\n","  if if_not_sloo is False:\n","    return model_rf.score(x_test,y_test)\n","\n","  print(\"Accuracy on train set Random Forest\",model_rf.score(x_train,y_train))\n","  print(\"Accuracy on test set Random Forest\",model_rf.score(x_test,y_test))\n","  pred_test_y_rf = model_rf.predict(x_test)\n","  print(\"Accuracy on the test set Random Forest\",accuracy_score(y_test,pred_test_y_rf))\n","  # 89% accuracy, \n","  # confusion matrix and Classification report\n","  cm_rf = confusion_matrix(y_test,pred_test_y_rf, labels=[1,0])\n","  cm_rf_df = pd.DataFrame(cm_rf,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_rf_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report Random Forest :\\n\",classification_report(y_test,pred_test_y_rf,labels=[1,0]))\n","  proab_test_y_rf = model_rf.predict_proba(x_test) \n","  fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test,proab_test_y_rf[:,1])\n","  #print(\"Area under the curve RF Model \", auc(fpr_rf,tpr_rf))\n","  print(\"ROC score for RF  Model: %.2f\"%roc_auc_score(y_test,pred_test_y_rf))\n","  plt.figure(figsize = [10,5])\n","  plt.plot(fpr_rf,tpr_rf,label=\"Random Forest\")\n","  #plt.plot(threshold_lr)\n","  #plt.plot(threshold_nb)\n","  #plt.plot(threshold_knn)\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0N9TXwfmeDIH"},"source":["from sklearn.ensemble import BaggingClassifier\n","\n","def bagging_classify(x_train,x_test,y_train,y_test,if_not_sloo = False):\n","  model_bgcl = BaggingClassifier(base_estimator=model_rf,n_estimators=50,random_state=0)\n","  model_bgcl.fit(x_train,y_train)\n","  if if_not_sloo is False:\n","    return model_bgcl.score(x_test,y_test)\n","  print(\"Accuracy on train set Bagging Classifier\",model_bgcl.score(x_train,y_train))\n","  print(\"Accuracy on test set Bagging Classifier\",model_bgcl.score(x_test,y_test))\n","  pred_test_y_bgcl = model_bgcl.predict(x_test)\n","  print(\"Accuracy on the test set Bagging Classifier\",accuracy_score(y_test,pred_test_y_bgcl))\n","\n","  cm_bgcl = confusion_matrix(y_test,pred_test_y_bgcl, labels=[1,0])\n","  cm_bgcl_df = pd.DataFrame(cm_bgcl,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_bgcl_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report Bagging Classifier with base estimator as RF :\\n\",classification_report(y_test,pred_test_y_bgcl,labels=[1,0]))\n","  # Recall of 1 - recall reduced to 92 in exp 2  \n","  # F1 score of 95 - reduced to 93 in exp 2 \n","  proab_test_y_bgcl = model_bgcl.predict_proba(x_test) \n","  fpr_bgcl, tpr_bgcl, threshold_bgcl = roc_curve(y_test,proab_test_y_bgcl[:,1])\n","  #print(\"Area under the curve Bagging classifier with RF as base Model \", auc(fpr_bgcl,tpr_bgcl))\n","  print(\"ROC score for Bagging classifier with RF as base Model: %.2f\"%roc_auc_score(y_test,pred_test_y_bgcl))\n","  plt.figure(figsize = [15,10])\n","  plt.plot(fpr_bgcl,tpr_bgcl,label=\"Bagging Clf (RF)\")\n","  #plt.plot(threshold_lr)\n","  #plt.plot(threshold_nb)\n","  #plt.plot(threshold_knn)\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYJilVM8eRs4"},"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","def adaboost(x_train,x_test,y_train,y_test,nest=50,rs=0,if_not_sloo=False):\n","  model_abcl = AdaBoostClassifier(n_estimators=nest,random_state=rs)\n","  model_abcl.fit(x_train,y_train)\n","  if if_not_sloo==False:\n","    return model_abcl.score(x_test,y_test)\n","    \n","  print(\"Accuracy on train set Adaboost Classifier\",model_abcl.score(x_train,y_train))\n","  print(\"Accuracy on test set Adaboost Classifier\",model_abcl.score(x_test,y_test))\n","  pred_test_y_abcl = model_abcl.predict(x_test)\n","  print(\"Accuracy on the test set Adaboost Classifier\",accuracy_score(y_test,pred_test_y_abcl))\n","  # confusion matrix and Classification report\n","  cm_abcl = confusion_matrix(y_test,pred_test_y_abcl, labels=[1,0])\n","  cm_abcl_df = pd.DataFrame(cm_abcl,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_abcl_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report Adaboost Classifier  :\\n\",classification_report(y_test,pred_test_y_abcl,labels=[1,0]))\n","  proab_test_y_abcl = model_abcl.predict_proba(x_test) \n","  fpr_abcl, tpr_abcl, threshold_abcl = roc_curve(y_test,proab_test_y_abcl[:,1])\n","  print(\"ROC score for Adaboost classifier : %.2f\"%roc_auc_score(y_test,pred_test_y_abcl))\n","  plt.figure(figsize = [15,10])\n","\n","  plt.plot(fpr_abcl,tpr_abcl,label=\"Adaboost Classifier\")\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtF57xZ1emDK"},"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","def gradient_boost(x_train,x_test,y_train,y_test,nest=50,rs=0,if_not_sloo=False):\n","  model_gbcl = GradientBoostingClassifier(n_estimators=nest,random_state=rs)\n","  model_gbcl.fit(x_train,y_train)\n","  if if_not_sloo==False:\n","    return model_gbcl.score(x_test,y_test)\n","    \n","  print(\"Accuracy on train set GradientBoosting Classifier\",model_gbcl.score(x_train,y_train))\n","  print(\"Accuracy on test set GradientBoosting Classifier\",model_gbcl.score(x_test,y_test))\n","  pred_test_y_gbcl = model_gbcl.predict(x_test)\n","  print(\"Accuracy on the test set GradientBoosting Classifier\",accuracy_score(y_test,pred_test_y_gbcl))\n","  # confusion matrix and Classification report\n","  cm_gbcl = confusion_matrix(y_test,pred_test_y_gbcl, labels=[1,0])\n","  cm_gbcl_df = pd.DataFrame(cm_gbcl,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_gbcl_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report Gradient Boosting Classifier  :\\n\",classification_report(y_test,pred_test_y_gbcl,labels=[1,0]))\n","  proab_test_y_gbcl = model_gbcl.predict_proba(x_test) \n","  fpr_gbcl, tpr_gbcl, threshold_gbcl = roc_curve(y_test,proab_test_y_gbcl[:,1])\n","  print(\"ROC score for Gradient Boosting classifier : %.2f\"%roc_auc_score(y_test,pred_test_y_gbcl))\n","  plt.figure(figsize = [15,10])\n","  plt.plot(fpr_gbcl,tpr_gbcl,label=\"Gradient Boosting\")\n","\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBe1tglRgalI"},"source":["from xgboost import XGBClassifier\n","\n","def xgboost_classifier(x_train,x_test,y_train,y_test,if_not_sloo=False):\n","  model_gbcl = XGBClassifier().fit(x_train, y_train)\n","  if if_not_sloo==False:\n","    return model_gbcl.score(x_test,y_test)\n","  print(\"Accuracy on train set XGB Classifier\",model_gbcl.score(x_train,y_train))\n","  print(\"Accuracy on test set CGB Classifier\",model_gbcl.score(x_test,y_test))\n","  pred_test_y_gbcl = model_gbcl.predict(x_test)\n","  print(\"Accuracy on the test set GradientBoosting Classifier\",accuracy_score(y_test,pred_test_y_gbcl))\n","  # confusion matrix and Classification report\n","  cm_gbcl = confusion_matrix(y_test,pred_test_y_gbcl, labels=[1,0])\n","  cm_gbcl_df = pd.DataFrame(cm_gbcl,columns=(i for i in [\"Predicted 1\",\"Predicted 0\"]),\n","                        index = (i for i in [1,0]))\n","  sns.heatmap(cm_gbcl_df, annot=True, cmap=\"YlGnBu\")\n","  print(\"\\nClassification report Gradient Boosting Classifier  :\\n\",classification_report(y_test,pred_test_y_gbcl,labels=[1,0]))\n","  proab_test_y_gbcl = model_gbcl.predict_proba(x_test) \n","  fpr_gbcl, tpr_gbcl, threshold_gbcl = roc_curve(y_test,proab_test_y_gbcl[:,1])\n","  print(\"ROC score for Gradient Boosting classifier : %.2f\"%roc_auc_score(y_test,pred_test_y_gbcl))\n","  plt.figure(figsize = [15,10])\n","  plt.plot(fpr_gbcl,tpr_gbcl,label=\"Gradient Boosting\")\n","\n","  plt.plot([0,1],[0,1],\"k--\")\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOEAEhPJa6ma"},"source":["imgz"]},{"cell_type":"code","metadata":{"id":"7FkGihKldtJv"},"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (8, 8)\n","plt.rcParams[\"figure.dpi\"] = 160\n","plt.rcParams[\"font.size\"] = 14\n","plt.rcParams['font.family'] = ['sans-serif']\n","plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n","plt.style.use('ggplot')\n","sns.set_style(\"whitegrid\", {'axes.grid': False})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUovq2gBa-N5"},"source":["import numpy as np\n","from skimage.io import imread\n","from skimage.util import montage as montage2d\n","import pandas as pd\n","from pathlib import Path\n","data_dir = Path(\"{}/drawings/all_together/\".format(fdir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDncojHxbM_f","outputId":"e3dc80a8-07c4-433f-ff3f-ed67d9700396"},"source":["from skimage.filters import threshold_yen as thresh_func\n","from skimage.filters import median\n","from skimage.morphology import disk, opening, diamond\n","\n","def read_and_thresh(in_path, resize=True):\n","    c_img = fixed_imread(in_path, resize=resize)\n","    c_img = (255*c_img).clip(0, 255).astype('uint8')\n","    c_img = median(c_img, disk(2))\n","    c_thresh = thresh_func(c_img)\n","    return c_img>c_thresh\n","\n","draw_df = pd.DataFrame({'path': list(data_dir.glob('./*/*/*.png'))})\n","draw_df['img_id'] = draw_df['path'].map(lambda x: x.stem)\n","draw_df['disease'] = draw_df['path'].map(lambda x: x.parent.stem)\n","draw_df['validation'] = draw_df['path'].map(lambda x: x.parent.parent.stem)\n","# draw_df['activity'] = draw_df['path'].map(lambda x: x.parent.parent.parent.stem)\n","print(draw_df.shape, 'images loaded')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(204, 4) images loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vnZfECfncPZp"},"source":["def fixed_imread(in_path, resize=True):\n","    \"\"\"read images, invert and scale them\"\"\"\n","    c_img = 1.0-imread(in_path, as_gray=True)\n","    max_dim = np.max(c_img.shape)\n","    if not resize:\n","        return c_img\n","    if c_img.shape==(256, 256):\n","        return c_img\n","    if max_dim>256:\n","        big_dim = 512\n","    else:\n","        big_dim = 256\n","        \n","    out_img = np.zeros((big_dim, big_dim), dtype='float32')\n","    c_offset = (big_dim-c_img.shape[0])//2\n","    d_offset = c_img.shape[0]+c_offset\n","    \n","    e_offset = (big_dim-c_img.shape[1])//2\n","    f_offset = c_img.shape[1]+e_offset\n","    out_img[c_offset:d_offset, e_offset:f_offset] = c_img[:(d_offset-c_offset), :(f_offset-e_offset)]\n","    return out_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vn5pOYEcSGT"},"source":["from skimage.filters import threshold_yen as thresh_func\n","from skimage.filters import median\n","from skimage.morphology import disk, opening, diamond\n","\n","def read_and_thresh(in_path, resize=True):\n","    c_img = fixed_imread(in_path, resize=resize)\n","    c_img = (255*c_img).clip(0, 255).astype('uint8')\n","    c_img = median(c_img, disk(2))\n","    c_thresh = thresh_func(c_img)\n","    return c_img>c_thresh\n","\n","draw_df['thresh_img'] = draw_df['path'].map(lambda x: read_and_thresh(x, resize=False))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7Ib9OFKdue-"},"source":["from skimage.morphology import label\n","from skimage.morphology import closing\n","def label_sort(in_img, cutoff=0.01):\n","    total_cnt = np.sum(in_img>0)\n","    lab_img = label(in_img)\n","    new_image = np.zeros_like(lab_img)\n","    remap_index = []\n","    for k in np.unique(lab_img[lab_img>0]):\n","        cnt = np.sum(lab_img==k)\n","        if cnt>total_cnt*cutoff:\n","            remap_index+=[(k, cnt)]\n","    sorted_index = sorted(remap_index, key=lambda x: -x[1])\n","    for new_idx, (old_idx, idx_count) in enumerate(sorted_index, 1):\n","        new_image[lab_img==old_idx] = new_idx\n","    return new_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAKh2S81dy66"},"source":["draw_df['clean_img'] = draw_df['thresh_img'].map(lambda x: closing(label_sort(x)>0, disk(2)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6v8v85Qhee69"},"source":["from skimage import data, color\n","from skimage.transform import rescale, resize, downscale_local_mean\n","from skimage.color import rgb2gray\n","\n","image = color.rgb2gray(data.astronaut())\n","\n","draw_df['grayscale'] = draw_df['clean_img'].map(lambda img : rgb2gray(img))\n","draw_df['resized'] = draw_df['clean_img'].map(lambda image: resize(image, (image.shape[0] // 1.4, image.shape[1] // 1.4)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVgXGI2-eT_Q"},"source":["from skimage.morphology import skeletonize\n","\n","fig, m_axs = plt.subplots(3, 3)\n","for c_ax, (c_lab, c_row) in zip(m_axs.flatten(), draw_df.sample(9).iterrows()):\n","    c_ax.imshow(c_row['grayscale'])\n","    # c_ax.imshow(c_row['clean_img'])\n","    c_ax.set_title('{disease}'.format(**c_row))\n","    c_ax.axis('off')\n","        # break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vv6MPJbpdavJ"},"source":["Image Analysis and CNN results"]},{"cell_type":"code","metadata":{"id":"Q4neOBSAdgXQ"},"source":["from keras.preprocessing.image import load_img, img_to_array\n","import os\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rg4aKlavdlxA"},"source":["# visualization\n","\n","plt.figure(figsize= (12,12))\n","for i in range(1, 10, 1):\n","    plt.subplot(3,3,i)\n","    cwd = os.getcwd()\n","    img = load_img(cwd + \"/archive/spiral/training/healthy/\" + os.listdir(cwd + \"/archive/spiral/training/healthy\")[i])\n","#     for img in os.listdir(cwd + \"/archive/spiral/training/healthy\"):\n","#         img = load_img(cwd + \"/archive/spiral/training/healthy/\" + img)\n","    plt.imshow(img)   \n","plt.show() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQaiOrNrdqXL"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","classifier=Sequential()\n","classifier.add(Conv2D(32,(3,3),input_shape=(128, 128, 3),activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","classifier.add(Conv2D(32,(3,3),activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","classifier.add(Flatten())\n","classifier.add(Dense(activation='relu',units=128))\n","classifier.add(Dense(activation='sigmoid',units=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeXcTiSYduBv"},"source":["train_datagen = ImageDataGenerator(rescale = 1./255, \n","                                  shear_range = 0.2, \n","                                  zoom_range = 0.2, \n","                                  horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-LnCKCedyKF"},"source":["spiral_train_generator = train_datagen.flow_from_directory(cwd + \"/archive/spiral/training/\",\n","                                                   target_size = (128,128),\n","                                                   batch_size = 20,\n","                                                   class_mode = 'binary')\n","\n","spiral_test_generator = test_datagen.flow_from_directory(cwd + \"/archive/spiral/testing/\",\n","                                                   target_size = (128,128),\n","                                                   batch_size = 20,\n","                                                   class_mode = 'binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"erNQygkrd12a"},"source":["wave_train_generator = train_datagen.flow_from_directory(cwd + \"/archive/wave/training/\",\n","                                                   target_size = (128,128),\n","                                                   batch_size = 20,\n","                                                   class_mode = 'binary')\n","\n","wave_test_generator = test_datagen.flow_from_directory(cwd + \"/archive/wave/testing/\",\n","                                                   target_size = (128,128),\n","                                                   batch_size = 20,\n","                                                   class_mode = 'binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbcQ6CSBd2c8"},"source":["from keras.optimizers import Adam\n","\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=3,verbose=1,restore_best_weights=True)\n","\n","reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,verbose=1,min_delta=0.0001)\n","\n","callbacks_list = [early_stopping,reduce_learningrate]\n","\n","epochs = 48\n","\n","classifier.compile(loss='binary_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2Mdwv_od4Vp"},"source":["history = classifier.fit_generator(\n","        spiral_train_generator,steps_per_epoch=spiral_train_generator.n//spiral_train_generator.batch_size,epochs=48,validation_data=spiral_test_generator,validation_steps=spiral_test_generator.n//spiral_test_generator.batch_size,callbacks=[early_stopping,reduce_learningrate])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tfx81fHld6-m"},"source":["plt.figure(figsize=(12,6))\n","plt.subplot(1,2,1)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.plot(history.history['accuracy'], label='Training Accuracy', color = 'green')\n","plt.legend(loc='lower right')\n","\n","\n","\n","plt.subplot(1,2,2)\n","plt.ylabel('Loss', fontsize=16)\n","plt.plot(history.history['loss'], label='Training Loss', color = 'red')\n","plt.legend(loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[]}]}